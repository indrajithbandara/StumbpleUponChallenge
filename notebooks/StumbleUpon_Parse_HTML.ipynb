{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re, json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(1231)\n",
    "\n",
    "DATA_DIR = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_processed = pd.read_csv('../data/processed/train_processed.csv')\n",
    "test_processed = pd.read_csv('../data/processed/test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat((train_processed, test_processed), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Notes **\n",
    "\n",
    "Beautiful Soup provides different parser library that can be used when we try to parse an html element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def soupify(urlid, parser='lxml'):\n",
    "    \"\"\"\n",
    "    Given a urlid fetches the corresponding html page\n",
    "    and creates a BeautifulSoup object out of it.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open('../data/raw/raw_content/' + str(urlid), 'rb') as infile:\n",
    "        html = infile.read()\n",
    "        \n",
    "        for parser in ['lxml', 'xml', 'html5lib']:\n",
    "            soup = BeautifulSoup(html, parser)\n",
    "            \n",
    "            if soup.body:\n",
    "                return soup\n",
    "        \n",
    "        infile.close()\n",
    "        \n",
    "        return BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TAGS = ['title', 'h1', 'h2', 'h3', 'meta-description', 'meta-keywords',\n",
    "        'img', 'a', 'other']\n",
    "    \n",
    "def get_content(soup_):\n",
    "    \"\"\"\n",
    "    Get all the content in the html\n",
    "    \"\"\"\n",
    "    \n",
    "    content = ''\n",
    "    \n",
    "    for d in soup_.find_all('div'):\n",
    "        content = d.text\n",
    "        content = re.sub(r'\\s+', ' ', content)\n",
    "    \n",
    "    return content\n",
    "\n",
    "def content_by_tag(soup_, tag_name):\n",
    "    \"\"\"\n",
    "    Return content given BeautifulSoup Object and tag name\n",
    "    \"\"\"\n",
    "    \n",
    "    items = []\n",
    "    \n",
    "    for el in soup_.find_all(tag_name):\n",
    "        if tag_name == 'img':\n",
    "            try:\n",
    "                items.append(unidecode(el['alt']))\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                items.append(unidecode(el['title']))\n",
    "            except KeyError:\n",
    "                pass\n",
    "        else:\n",
    "            items.append(el.text)\n",
    "    \n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_string(s):\n",
    "    s = s.encode('utf-8')\n",
    "    s = unidecode(s).lower()\n",
    "    s = re.sub(r'\\s+', ' ', s)\n",
    "    \n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump_data(data):\n",
    "    with open('../data/processed/extracted_text', 'w') as outfile:\n",
    "        sys.stdout = outfile\n",
    "        \n",
    "        for i, item in enumerate(data):\n",
    "            # status update\n",
    "            \n",
    "            parsed_data = {}\n",
    "            soup_ = soupify(item['urlid'])\n",
    "            \n",
    "            # given boilerplate\n",
    "            parsed_data['boilerplate'] = [item['title'], item['body']]\n",
    "            \n",
    "            # extract text\n",
    "            parsed_data['boilerpipe'] = get_content(soup_)\n",
    "            \n",
    "            # extract tag for each text\n",
    "            for tag in TAGS:\n",
    "                parsed_data[tag] = content_by_tag(soup_, tag)\n",
    "            \n",
    "            meta = soup_.find_all('meta')\n",
    "            \n",
    "            for el in meta:\n",
    "                prop = el.get('property') if el.get('property') else el.get('name')\n",
    "\n",
    "                if not prop:\n",
    "                    continue\n",
    "\n",
    "                prop = prop.lower()\n",
    "\n",
    "                try:\n",
    "                    s = el['content']\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "                parsed_data['meta-'+prop] = s.split(u',') if prop == 'keywords' else s \n",
    "            \n",
    "            # preprocess string\n",
    "            for item in parsed_data:\n",
    "                parsed_data[item] = map(clean_string, parsed_data[item])\n",
    "                parsed_data[item] = filter(None, parsed_data[item])\n",
    "            \n",
    "            print(json.dumps(parsed_data))\n",
    "        \n",
    "        outfile.close()\n",
    "\n",
    "# dump data\n",
    "dump_data(data)\n",
    "\n",
    "# set the stdout back to original state\n",
    "sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
