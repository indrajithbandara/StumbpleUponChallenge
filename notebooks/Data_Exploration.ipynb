{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data presented to us has both numerical as well as text based features.__\n",
    "\n",
    "*Objectives of this notebook.*\n",
    "\n",
    "* Whether numerical features are any significant or not.\n",
    "\n",
    "* Whether we should parse raw content or not ?\n",
    "* Is boilerplate code sufficient enough to capture detailed intricacies in the data ?\n",
    "* Learn a whole lot new text mining techniques.\n",
    "* Learn how to run processes in parallel, which is very important when we want to quickly iterate through our various ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Evaluation Metric - AUC ( Area Under Curve ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re, json\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD as SVD\n",
    "from sklearn.preprocessing import StandardScaler, scale, MinMaxScaler\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('poster')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# set seed\n",
    "np.random.seed(1)\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/Stumbleupon_classification_challenge/')\n",
    "sys.path.append(os.path.join(basepath, 'src'))\n",
    "\n",
    "from models import train_test_split, cross_val_scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load files\n",
    "train = pd.read_csv(os.path.join(basepath, 'data/raw/train.tsv'), delimiter='\\t')\n",
    "test = pd.read_csv(os.path.join(basepath, 'data/raw/test.tsv'), delimiter='\\t')\n",
    "sample_sub = pd.read_csv(os.path.join(basepath, 'data/raw/sampleSubmission.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove urlid from the train and test and store them in separate variable\n",
    "def fetch_urlid(data):\n",
    "    return data['urlid']\n",
    "\n",
    "def delete_urlid(data):\n",
    "    del data['urlid']\n",
    "\n",
    "train_urlid = fetch_urlid(train)\n",
    "test_urlid = fetch_urlid(test)\n",
    "\n",
    "delete_urlid(train)\n",
    "delete_urlid(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Helper Functions **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_variable(train, test):\n",
    "    \"\"\"\n",
    "    Convert categorical variable to numerical form\n",
    "    \n",
    "    train: Values of the variable in the training set\n",
    "    test: Values of the variable  in the test set\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.concat((train, test), axis=0)\n",
    "    \n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(data)\n",
    "    \n",
    "    train_ = lbl.transform(train)\n",
    "    test_ = lbl.transform(test)\n",
    "    \n",
    "    return train_, test_\n",
    "\n",
    "def store(filename, data):\n",
    "    \"\"\"\n",
    "    Pickle data onto disk\n",
    "    \n",
    "    filename: filename that you want to give to this dump\n",
    "    data: actual data that you want to dump.\n",
    "    \"\"\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(os.path.join(basepath, 'data/processed/') + filename, 'wb') as outfile:\n",
    "        pickle.dump(data, outfile, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        outfile.close()\n",
    "        \n",
    "def load(filename):\n",
    "    \"\"\"\n",
    "    Load data from disk\n",
    "    \n",
    "    filename: filename of the pickled data that you want to load\n",
    "    \"\"\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    with open(os.path.join(basepath, 'data/processed/') + filename, 'rb') as infile:\n",
    "        data = pickle.load(infile)\n",
    "        infile.close()\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's see the url variable. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Lets create a variable which counts the depth in the url. **\n",
    "\n",
    "e.g. www.guardian.co.uk/a has depth 1, whereas www.guardian.co.uk/a/b has depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def url_depth(url):\n",
    "    \"\"\"\n",
    "    Takes in a url and calculates depth\n",
    "    e.g. www.guardian.co.uk/a has depth 1, whereas www.guardian.co.uk/a/b has depth 2\n",
    "    \n",
    "    url - url of the webpage\n",
    "    \"\"\"\n",
    "    \n",
    "    parsed_url = urlparse(url)\n",
    "    path = parsed_url.path\n",
    "\n",
    "    return len(list(filter(lambda x: len(x)> 0, path.split('/'))))\n",
    "\n",
    "url_depths = train.url.map(url_depth)\n",
    "url_depths_test = test.url.map(url_depth)\n",
    "\n",
    "assert len(url_depths) == len(train)\n",
    "assert len(url_depths_test) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_df = pd.DataFrame({'url_depths': url_depths, 'label': train.label})\n",
    "feature_df_test = pd.DataFrame({'url_depths': url_depths_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Validate the hypothesis that this feature is actually indicative or not. **\n",
    "\n",
    "1. Split the dataset into training and test set\n",
    "2. Set up a cross validation scheme.\n",
    "3. Record the final performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.615551\n",
       "?    0.384449\n",
       "Name: is_news, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_news.value_counts() / train.is_news.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.613687\n",
       "?    0.386313\n",
       "Name: is_news, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.is_news.value_counts() / test.is_news.value_counts().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Since the ratio of the news article to other articles is somewhat constant in training and test sets is constant, we have to make sure that this ratio is preserved in the differnt folds we create during the cross-validation so that our dataset is representative of the original set. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 2,\n",
    "    'stratify': train.is_news\n",
    "}\n",
    "\n",
    "features = ['url_depths']\n",
    "\n",
    "itrain, itest = train_test_split.tr_ts_split(len(train), **params)\n",
    "\n",
    "X_train = feature_df.iloc[itrain][features].values\n",
    "X_test = feature_df.iloc[itest][features].values\n",
    "\n",
    "y_train = feature_df.iloc[itrain].label.values\n",
    "y_test = feature_df.iloc[itest].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [ 0.52118866  0.54039943  0.52608173]\n",
      "Mean CV Score: 0.529223\n",
      "Std Cv Scoes: 0.008151\n"
     ]
    }
   ],
   "source": [
    "# cross validation scheme\n",
    "est = LogisticRegression()\n",
    "\n",
    "params = {\n",
    "    'n_folds': 3,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "is_news = train.iloc[itrain].is_news\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train, is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on the held out set: 0.531968 \n"
     ]
    }
   ],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard score - 0.54425** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "est.fit(feature_df[['url_depths']], feature_df.label)\n",
    "predictions = est.predict_proba(feature_df_test[['url_depths']])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top Level Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_top_level_domain(url):\n",
    "    \"\"\"\n",
    "    Extracts top level domain from a given url\n",
    "    \n",
    "    url: Url of the webpage in the dataset\n",
    "    \"\"\"\n",
    "    parsed_url = urlparse(url)\n",
    "    top_level = parsed_url[1].split('.')[-1]\n",
    "    \n",
    "    return top_level\n",
    "    \n",
    "top_level_domains_train = train.url.map(extract_top_level_domain)\n",
    "top_level_domains_test = test.url.map(extract_top_level_domain)\n",
    "\n",
    "assert len(top_level_domains_train) == len(train)\n",
    "assert len(top_level_domains_test) == len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tld_encode_train, tld_encoded_test = encode_variable(top_level_domains_train, top_level_domains_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df['tld'] = tld_encode_train\n",
    "feature_df_test['tld'] = tld_encoded_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 2,\n",
    "    'stratify': train.is_news\n",
    "}\n",
    "\n",
    "features = ['url_depths', 'tld']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split.tr_ts_split(feature_df[features], feature_df['label'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation scheme\n",
    "est = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "params = {\n",
    "    'n_folds': 3,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train, train.is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard Score: 0.61713**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "est.fit(feature_df[features], feature_df.label)\n",
    "predictions = est.predict_proba(feature_df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whether webpage belongs to news category or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_is_news, test_is_news = encode_variable(train.is_news, test.is_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df['is_news'] = train_is_news\n",
    "feature_df_test['is_news'] = test_is_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 2,\n",
    "    'stratify': train.is_news\n",
    "}\n",
    "\n",
    "features = ['url_depths', 'tld', 'is_news']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split.tr_ts_split(feature_df[features], feature_df['label'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation scheme\n",
    "est = RandomForestClassifier(n_estimators=50, max_depth=10, n_jobs=-1)\n",
    "\n",
    "params = {\n",
    "    'n_folds': 3,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train, train.is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard Score: 0.60854 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "est.fit(feature_df[features], feature_df.label)\n",
    "predictions = est.predict_proba(feature_df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alchemy Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alchemy_category_train, alchemy_category_test = encode_variable(train.alchemy_category, test.alchemy_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_df['alchemy_category'] = alchemy_category_train\n",
    "feature_df_test['alchemy_category'] = alchemy_category_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 2,\n",
    "    'stratify': train.is_news\n",
    "}\n",
    "\n",
    "features = ['url_depths', 'tld', 'alchemy_category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split.tr_ts_split(feature_df[features], feature_df['label'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cross validation scheme\n",
    "est = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "params = {\n",
    "    'n_folds': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train, train.is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard Score: 0.67329 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "est.fit(feature_df[features], feature_df.label)\n",
    "predictions = est.predict_proba(feature_df_test[features])[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_json(text):\n",
    "    return json.loads(text)\n",
    "\n",
    "def extract_body(json_):\n",
    "    return json_['body'] if json_['body'] else u''\n",
    "\n",
    "converted_json_train = train.boilerplate.map(convert_to_json)\n",
    "converted_json_test = test.boilerplate.map(convert_to_json)\n",
    "\n",
    "body_train = list(map(extract_body, converted_json_train))\n",
    "body_test = list(map(extract_body, converted_json_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(strip_accents='unicode')\n",
    "tfidf.fit(body_train)\n",
    "\n",
    "body_train_tfidf = tfidf.transform(body_train)\n",
    "body_test_tfidf = tfidf.transform(body_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** This takes considerable amount of memory resource to generate these tfidf features so it is advisable to dump them once you have computed them. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "store('train_text_features', body_train_tfidf)\n",
    "store('test_text_features', body_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body_train_tfidf = load('train_text_features')\n",
    "body_test_tfidf = load('test_text_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features captured in the body of the boilerplate: 85131\n"
     ]
    }
   ],
   "source": [
    "print('Number of features captured in the body of the boilerplate: %d'%body_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure number of features captured in both training and test dataset are same\n",
    "assert(body_train_tfidf.shape[1] == body_test_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 85131 feature are way too many features, so we have to bring down the dimensionality of the problem. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd = SVD(n_components=120)\n",
    "svd.fit(body_train_tfidf)\n",
    "\n",
    "features_train = svd.transform(body_train_tfidf)\n",
    "features_test = svd.transform(body_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced number of features are: 120\n"
     ]
    }
   ],
   "source": [
    "print('Reduced number of features are: %d'%features_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'test_size': 0.2,\n",
    "    'random_state': 2,\n",
    "    'stratify': train.is_news\n",
    "}\n",
    "\n",
    "itrain, itest = train_test_split.tr_ts_split(len(train), **params)\n",
    "\n",
    "X_train = features_train[itrain]\n",
    "X_test = features_train[itest]\n",
    "\n",
    "y_train = feature_df.iloc[itrain].label\n",
    "y_test = feature_df.iloc[itest].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "select = SelectKBest(chi2, k=50)\n",
    "select.fit(X_train, y_train)\n",
    "\n",
    "X_train = select.transform(X_train)\n",
    "X_test = select.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [ 0.84160067  0.86644798  0.875675    0.87799708  0.86926143]\n",
      "Mean CV Score: 0.866196\n",
      "Std Cv Scoes: 0.012989\n"
     ]
    }
   ],
   "source": [
    "# cross validation scheme\n",
    "est = LogisticRegression(C=1.)\n",
    "\n",
    "params = {\n",
    "    'n_folds': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "is_news = train.iloc[itrain].is_news\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train.values, is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard Score: 0.86785 ( w/o scaling ) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on the held out set: 0.854838 \n"
     ]
    }
   ],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train.values)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(features_train)\n",
    "\n",
    "features_train = scaler.transform(features_train)\n",
    "features_test = scaler.transform(features_test)\n",
    "\n",
    "select = SelectKBest(chi2, k=50)\n",
    "select.fit(features_train, feature_df.label.values)\n",
    "\n",
    "features_train = select.transform(features_train)\n",
    "features_test = select.transform(features_test)\n",
    "\n",
    "est.fit(features_train, feature_df.label.values)\n",
    "predictions = est.predict_proba(features_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How to combine textual features with numerical features? **\n",
    "\n",
    "Use _numpy.hstack_ to concatenate textual features with numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_concat_train = np.hstack((features_train, feature_df[features].values))\n",
    "features_concat_test = np.hstack((features_test, feature_df_test[features].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = features_concat_train[itrain]\n",
    "X_test = features_concat_train[itest]\n",
    "\n",
    "y_train = feature_df.iloc[itrain].label.values\n",
    "y_test = feature_df.iloc[itest].label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler()\n",
    "min_max.fit(X_train)\n",
    "# scaler = StandardScaler()\n",
    "# scaler.fit(X_train)\n",
    "\n",
    "X_train = min_max.transform(X_train)\n",
    "X_test = min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores: [ 0.83517829  0.8647036   0.86734052  0.87780567  0.86454116]\n",
      "Mean CV Score: 0.861914\n",
      "Std Cv Scoes: 0.014223\n"
     ]
    }
   ],
   "source": [
    "# cross validation scheme\n",
    "est = LogisticRegression(C=.8)\n",
    "\n",
    "params = {\n",
    "    'n_folds': 5,\n",
    "    'shuffle': True,\n",
    "    'random_state': 3\n",
    "}\n",
    "\n",
    "is_news = train.iloc[itrain].is_news\n",
    "scores, mean_score, std_score = cross_val_scheme.cv_scheme(est, X_train, y_train, is_news, **params)\n",
    "\n",
    "print('CV Scores: %s'%(scores))\n",
    "print('Mean CV Score: %f'%(mean_score))\n",
    "print('Std Cv Scoes: %f'%(std_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Private Leaderboard score: 0.78387 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC score on the held out set: 0.856604 \n"
     ]
    }
   ],
   "source": [
    "# performance on the held out test set\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print('ROC AUC score on the held out set: %f '%(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on full dataset\n",
    "min_max = MinMaxScaler()\n",
    "min_max.fit(features_concat_train)\n",
    "\n",
    "features_concat_train = min_max.transform(features_concat_train)\n",
    "feature_concat_test = min_max.transform(features_concat_test)\n",
    "\n",
    "est.fit(features_concat_train, feature_df.label.values)\n",
    "predictions = est.predict_proba(features_concat_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub['label'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv(os.path.join(basepath, 'submissions/text_features_100_features.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
